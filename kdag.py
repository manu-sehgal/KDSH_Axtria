# -*- coding: utf-8 -*-
"""Kdag

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ajJ4wZ2loVVNiMsA_9iM1ColSPkdEacu
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('/content/KDAG.csv')
df

df.iloc[0,6]

df['Physician_Segment'].unique()

df = df[['Brand_Rx', 'Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered', 'Market_Rx']]
df

def normalize(df):
    result = df.copy()
    for feature_name in df.columns:
        max_value = df[feature_name].max()
        min_value = df[feature_name].min()
        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
    return result

df = normalize(df)

df

sub = pd.read_csv('sample_submission.csv')
sub

sub_brand=pd.read_csv('sample_brand.csv')
sub_brand

for k in range(10000):
  if(k % 1000 == 0):
    print(k)
  start = k * 57
  data = df.iloc[start:start + 57,:]
  # display(data)
  data = data[['Brand_Rx', 'Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered', 'Market_Rx']]

  train = data[:int(0.8*(len(data)))]
  valid = data[int(0.8*(len(data))):]

  #fit the model
  from statsmodels.tsa.vector_ar.var_model import VAR

  model = VAR(endog=train)
  model_fit = model.fit(trend='nc')

  # make prediction on validation
  prediction = model_fit.forecast(model_fit.y, steps=len(valid))

  model = VAR(endog=data)
  model_fit = model.fit(trend='nc')
  yhat = model_fit.forecast(model_fit.y, steps=1)

  call = data.iloc[4:,1].sum()

  if(yhat[0][0] != 0):
    sub_brand.iloc[k,1] = yhat[0][0]
  
  else:
    if df.iloc[start,6] == '3-Low':
      sub_brand.iloc[k,1] = 0.245 / 2
    elif df.iloc[start,6] == '2-Medium':
      sub_brand.iloc[k,1] = 0.520 / 2
    else:
      sub_brand.iloc[k,1] = 1.770 / 2

  if(yhat[0][1] >= yhat[0][2] and yhat[0][1] >= yhat[0][3]):
    if df.iloc[start,6] == '3-Low' and call > 12:
      sub.iloc[k,1] = 1
    elif df.iloc[start,6] == '2-Medium' and call > 24:
      sub.iloc[k,1] = 1
    elif df.iloc[start,6] == '1-High' and call > 48:
      sub.iloc[k,1] = 1
    else:
      sub.iloc[k,1] = 0
  
  elif(yhat[0][2] >= yhat[0][3]):
    sub.iloc[k,1] = 1
  
  else:
    sub.iloc[k,1] = 2

df = pd.read_csv('HCP_Data_KDAG_Hackathon.csv')
df

df.tail()

semi=np.zeros((10000,6))
semi

#harsh..... with constraints


for k in range(10000):
  if(k % 1000 == 0):
    print(k)
  start = k * 57
  data = df.iloc[start:start + 58,:]
  # display(data)
  #data = data[['Brand_Rx', 'Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered', 'Market_Rx']]
  data = data[['Brand_Rx', 'Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered']]

  train = data[:int(0.8*(len(data)))]
  valid = data[int(0.8*(len(data))):]

  #fit the model
  from statsmodels.tsa.vector_ar.var_model import VAR

  model = VAR(endog=train)
  model_fit = model.fit(trend='nc')

  # make prediction on validation
  prediction = model_fit.forecast(model_fit.y, steps=len(valid))

  model = VAR(endog=data)
  model_fit = model.fit(trend='nc')
  yhat = model_fit.forecast(model_fit.y, steps=2)

  call = data.iloc[5:,1].sum()

  semi[k][0]=yhat[0][1]+yhat[0][3]-2*yhat[0][2]    # call+mail-2*drops
  semi[k][1]=yhat[0][1]  #calls
  semi[k][2]=yhat[0][2]  #drops
  semi[k][3]=yhat[0][3]  #mails
  semi[k][4]=call
  semi[k][5]=k

semi_sorted=semi[semi[:,0].argsort()]
semi_sorted
semi=semi_sorted

count_drop=0
max_drop=2500
for k in range(10000):
  if(k % 1000 == 0):
    print(k)
  if(semi[k][2]>semi[k][1] and semi[k][2]>semi[k][3]):
    count_drop=count_drop+1
diff=max_drop-count_drop
print(diff)

sub = pd.read_csv('sample_submission.csv')
sub

count=0
blah=0
for k in range(10000):
  #start = k * 57
  ind=int(semi[k][5])
  if(k % 1000 == 0):
    print(k)
  if(semi[k][2] > semi[k][1] and semi[k][2] >= semi[k][3] and count<2500):
    sub.iloc[ind,1] = 1
    count+=1
  elif(semi[k][1] >= semi[k][3]):
    if df.iloc[start,6] == '3-Low' and semi[k][4] <= 12:
      sub.iloc[ind,1] = 0
    elif df.iloc[start,6] == '2-Medium' and semi[k][4] <= 24:
      sub.iloc[ind,1] = 0
    elif df.iloc[start,6] == '1-High' and semi[k][4] <= 48:
      sub.iloc[ind,1] = 0
    else:
      if(semi[k][2] >= semi[k][3] and count<2500):
        sub.iloc[ind,1] = 1
        count+=1
      else:
        sub.iloc[ind,1] = 2
  elif(semi[k][2] >= semi[k][3] and count<2500):
    sub.iloc[ind,1] = 1
    count+=1
  else:
    sub.iloc[ind,1] = 2

count=0
for k in range(10000):
  ind=int(semi[k][5])
  start = k * 57
  if(k % 1000 == 0):
    print(k)
  if(semi[k][1] >= semi[k][2] and semi[k][1] >= semi[k][3]):
    if df.iloc[start,6] == '3-Low' and semi[k][4] >= 10:
      sub.iloc[ind,1] = 2
    elif df.iloc[start,6] == '2-Medium' and semi[k][4] >= 10:
      sub.iloc[ind,1] = 2
    elif df.iloc[start,6] == '1-High' and semi[k][4] >= 10:
      sub.iloc[ind,1] = 2
    else:
      sub.iloc[ind,1] = 0
  
  elif(semi[k][2] > semi[k][3] and count<2500):
    sub.iloc[ind,1] = 1
    count+=1
  
  else:
    sub.iloc[ind,1] = 2

count=0
for k in range(9999,-1,-1):
  if(k % 1000 == 0):
    print(k)
  if(semi[k][1] >= semi[k][2] and semi[k][1] >= semi[k][3]):
    if df.iloc[start,6] == '3-Low' and semi[k][4] >= 12:
      sub.iloc[k,1] = 2
    elif df.iloc[start,6] == '2-Medium' and semi[k][4] >= 24:
      sub.iloc[k,1] = 2
    elif df.iloc[start,6] == '1-High' and semi[k][4] >= 48:
      sub.iloc[k,1] = 2
    else:
      sub.iloc[k,1] = 0
  
  elif(semi[k][2] > semi[k][3] and count<2500):
    sub.iloc[k,1] = 1
    count+=1
  
  else:
    sub.iloc[k,1] = 2

sub

sub['Channel'].value_counts()

sub.to_csv('hs_2.csv', index = False)

sub_brand

sub_brand.to_csv('ts_brand.csv', index = False)

sub_brand['Expected_TRx'].max()

from numpy import array

data = df.iloc[:57,:]

data = data[['Brand_Rx', 'Sales_Rep_Calls', 'Samples_Dropped', 'Emails_Delivered']]

def split_sequence(sequence, n_steps):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(sequence)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)

# define input sequence
raw_seq = data['Brand_Rx'].values
# choose a number of time steps
n_steps = 3
# split into samples
X, y = split_sequence(raw_seq, n_steps)
# summarize the data
for i in range(len(X)):
	print(X[i], y[i])

from numpy import array
from keras.models import Sequential
from keras.layers import LSTM
from keras.layers import Dense
 
# split a univariate sequence into samples
def split_sequence(sequence, n_steps):
	X, y = list(), list()
	for i in range(len(sequence)):
		# find the end of this pattern
		end_ix = i + n_steps
		# check if we are beyond the sequence
		if end_ix > len(sequence)-1:
			break
		# gather input and output parts of the pattern
		seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
		X.append(seq_x)
		y.append(seq_y)
	return array(X), array(y)
 
for j in range(4):
  # define input sequence
  raw_seq = data.iloc[:,j].values
  # choose a number of time steps
  n_steps = 3
  # split into samples
  X, y = split_sequence(raw_seq, n_steps)
  # reshape from [samples, timesteps] into [samples, timesteps, features]
  n_features = 1
  X = X.reshape((X.shape[0], X.shape[1], n_features))
  # define model
  model = Sequential()
  model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))
  model.add(Dense(1))
  model.compile(optimizer='adam', loss='mse')
  # fit model
  model.fit(X, y, epochs=200, verbose=0)
  # demonstrate prediction
  x_input = data.iloc[54:,j].values
  x_input = x_input.reshape((1, n_steps, n_features))
  yhat = model.predict(x_input, verbose=0)
  print(yhat)

data.loc[54:,'Brand_Rx'].values



from statsmodels.tsa.vector_ar.var_model import VAR
from sklearn.metrics import mean_squared_error

train = data[:int(0.8*(len(data)))]
valid = data[int(0.8*(len(data))):]

#fit the model
from statsmodels.tsa.vector_ar.var_model import VAR

model = VAR(endog=train)
model_fit = model.fit()

# make prediction on validation
prediction = model_fit.forecast(model_fit.y, steps=len(valid))

cols = data.columns

#converting predictions to dataframe
pred = pd.DataFrame(index=range(0,len(prediction)),columns=[cols])
for j in range(0,4):
    for i in range(0, len(prediction)):
       pred.iloc[i][j] = prediction[i][j]

#check mse
for i in cols:
    print('mse value for', i, 'is : ', mean_squared_error(pred[i], valid[i]))

model = VAR(endog=data)
model_fit = model.fit()
yhat = model_fit.forecast(model_fit.y, steps=1)
print(yhat)

yhat[0][0]

df_new = df
df_new['Sales_Rep_Calls'] = (df_new['Sales_Rep_Calls'] > 0).astype(int)
df_new['Samples_Dropped'] = (df_new['Samples_Dropped'] > 0).astype(int)
df_new['Emails_Delivered'] = (df_new['Emails_Delivered'] > 0).astype(int)

df = df_new

sub = pd.read_csv('/content/Sample.csv')
sub

df1 = df[df.index % 57 == 4]
df1

df1.info()

for i in range(len(df1)):
  if df1.iloc[i,4] == 0 and df1.iloc[i,7] == 0 and df1.iloc[i,5] == 0:
    sub.iloc[i,1] = np.random.choice(3,1,p=[0.6, 0.2, 0.2])
  elif df1.iloc[i,4] >= df1.iloc[i,7] and df1.iloc[i,4] >= df1.iloc[i,5]:
    sub.iloc[i,1] = 0
  # elif df1.iloc[i,7] >= df1.iloc[i,5]:
  #   sub.iloc[i,1] = 2
  else:
    sub.iloc[i,1] = np.random.choice([1,2],1)

sub['Channel'].value_counts()

sub.to_csv('sub_feb.csv', index = False)



s = pd.read_csv('/content/sample_submission.csv')
s

for i in range(len(df1)):
  s.iloc[i,1] = df1.iloc[i,2]

s

"""**##a1b1+a2b2+a3b3 approach##**

"""

import pandas as pd
import numpy as np
from pandas import read_excel

df = pd.read_csv('HCP_Data_KDAG_Hackathon.csv')
df

df_new = df
df_new['Sales_Rep_Calls'] = (df_new['Sales_Rep_Calls'] > 0).astype(int)
df_new['Samples_Dropped'] = (df_new['Samples_Dropped'] > 0).astype(int)
df_new['Emails_Delivered'] = (df_new['Emails_Delivered'] > 0).astype(int)

df=df_new
df

sub = pd.read_csv('sample_submission.csv')

sub_brand=pd.read_csv('sample_brand.csv')

for k in range(10000):
  if(k%1000==0):
    print(k)
  start=k*57
  sum=0.0
  count=0
  for j in range(4,57):
    if(start+j<=len(df)):
      value=df.iloc[start+j,2]
      if(value>0):
        sum=sum+value
        count=count+1
  
  if(count):
    avg=sum/53
    sub_brand.iloc[k,1]=1* avg
    """
  else:
    if df.iloc[start,6] == '3-Low':
      sub_brand.iloc[k,1] = 0.245 / 2
    elif df.iloc[start,6] == '2-Medium':
      sub_brand.iloc[k,1] = 0.520 / 2
    else:
      sub_brand.iloc[k,1] = 1.770 / 2
      """

sub_brand.to_csv('brandavg_1.csv',index=False)

sub['Channel'].value_counts()

sub

sub_brand

sub.to_csv('sub_weight_6.csv',index=False)

for k in range(10000):
  if(k%1000==0):
    print(k)
  start=k*57
  f_call,f_drop,f_mail=0,0,0
  score_call,score_drop,score_mail=0.0,0.0,0.0
  for j in range(57):
    if(start+j<=len(df)):
      value=df.iloc[start+j,2]
      tot_value=df.iloc[start+j,3]
      
      f1=df.iloc[start+j,4]
      f2=df.iloc[start+j,5]
      f3=df.iloc[start+j,7]
      
      sum=0
      sum=f1+f2+f3
      f_call=f_call+f1
      f_drop=f_drop+f2
      f_mail=f_mail+f3
      frac=0.0
      if(sum>0 and tot_value>0):
        frac=value/tot_value
        score_call=score_call+f_call*frac/sum
        score_drop=score_drop+f_drop*frac/sum
        score_mail=score_mail+f_mail*frac/sum
    
  #AS denotes average score
  AS_call,AS_drop,AS_mail=0.0,0.0,0.0
  if(f_call):
    AS_call=score_call/f_call
  if(f_drop):
    AS_drop=score_drop/f_drop
  if(f_mail):
    AS_mail=score_mail/f_mail

  if(AS_call>=AS_drop and AS_call>=AS_mail):
    sub.iloc[k,1] = 0
    sub_brand.iloc[k,1]= AS_call
  elif(AS_drop>=AS_mail):
    sub.iloc[k,1] = 1
    sub_brand.iloc[k,1]= AS_drop
  else:
    sub.iloc[k,1] = 2
    sub_brand.iloc[k,1]= AS_mail



def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
  n_vars = 1 if type(data) is list else data.shape[1]
  df = DataFrame(data)
  cols, names = list(), list()
  # input sequence (t-n, ... t-1)
  for i in range(n_in, 0, -1):
  cols.append(df.shift(i))
  names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
  # forecast sequence (t, t+1, ... t+n)
  for i in range(0, n_out):
  cols.append(df.shift(-i))
  if i == 0:
  names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
  else:
  names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
  # put it all together
  agg = concat(cols, axis=1)
  agg.columns = names
  # drop rows with NaN values
  if dropnan:
  agg.dropna(inplace=True)
  return agg

dataset = read_csv('pollution.csv', header=0, index_col=0)
values = dataset.values
# integer encode direction
encoder = LabelEncoder()
values[:,4] = encoder.fit_transform(values[:,4])
# ensure all data is float
values = values.astype('float32')
# normalize features
scaler = MinMaxScaler(feature_range=(0, 1))
scaled = scaler.fit_transform(values)
# frame as supervised learning
reframed = series_to_supervised(scaled, 1, 1)
# drop columns we don't want to predict
reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)
print(reframed.head())